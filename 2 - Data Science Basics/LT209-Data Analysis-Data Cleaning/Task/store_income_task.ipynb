{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[],"source":["# Load up store_income_data.csv\n","\n","import pandas as pd\n","import numpy as np\n","import fuzzywuzzy\n","from fuzzywuzzy import process\n","import chardet\n","import datetime\n","from datetime import date\n","\n","df = pd.read_csv('store_income_data_task.csv')"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":63,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 13 unique countries\n"]},{"data":{"text/plain":["array(['united states', 'britain', 'united kingdom', 'u.k', 'sa',\n","       'america', nan, 's.a', 'england', 'uk', '',\n","       'united states of america', 's. africasouth africa'], dtype=object)"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["df.head()\n","\n","df['country'] = df['country'].str.lower()\n","\n","df['country'] = df['country'].str.strip()\n","df['country'] = df['country'].str.strip('/')\n","df['country'] = df['country'].str.strip('.')\n","\n","countries = df['country'].unique()\n","print(f\"There are {len(countries)} unique countries\")\n","countries\n"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":64,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final unique country values: ['united states' 'united kingdom' 'south africa']\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/m7/3y4fdpjn45qdddmm1wfk91x40000gn/T/ipykernel_60953/2709251610.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['country'].replace(['', 'nan', None], np.nan, inplace=True)\n"]}],"source":["import fuzzywuzzy\n","from fuzzywuzzy import process\n","import chardet\n","\n","# Step 3: Replace country variations with consistent names\n","\n","# Define a function to replace matches in the \"country\" column based on a minimum similarity ratio\n","def replace_matches_in_column(df, column, string_to_match, min_ratio=90):\n","    # Get unique country names\n","    unique_strings = df[column].unique()\n","    \n","    # Use fuzzy matching to find similar country names\n","    matches = process.extract(string_to_match, unique_strings, limit=100, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","    \n","    # Filter matches that meet the minimum ratio\n","    close_matches = [match[0] for match in matches if match[1] >= min_ratio]\n","    \n","    # Replace close matches with the specified standard country name\n","    df.loc[df[column].isin(close_matches), column] = string_to_match\n","\n","df['country'].replace(['', 'nan', None], np.nan, inplace=True)\n","                      \n","# Apply the replacement function to ensure only three standard country names remain\n","replace_matches_in_column(df, 'country', 'south africa')\n","replace_matches_in_column(df, 'country', 'united kingdom')\n","replace_matches_in_column(df, 'country', 'united states')\n","\n","df.replace('britain', 'united kingdom', inplace=True)\n","df.replace('u.k', 'united kingdom', inplace=True)\n","df.replace('uk', 'united kingdom', inplace=True)\n","df.replace('england', 'united kingdom', inplace=True)\n","df.replace('sa', 'south africa', inplace=True)\n","df.replace('s.a', 'south africa', inplace=True)\n","df.replace('s. africasouth africa', 'south africa', inplace=True)\n","df.replace('america', 'united states', inplace=True)\n","df.replace('united states of america', 'united states', inplace=True)\n","\n","df.dropna(subset=['country'], inplace=True)\n","\n","unique_countries = df['country'].unique()\n","print(f\"Final unique country values: {unique_countries}\")\n"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":65,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","      <th>days_ago</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>2006-02-04</td>\n","      <td>united states</td>\n","      <td>6862</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>2006-01-04</td>\n","      <td>united kingdom</td>\n","      <td>6893</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>2003-09-12</td>\n","      <td>united states</td>\n","      <td>7738</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>2006-05-08</td>\n","      <td>united kingdom</td>\n","      <td>6769</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>1973-01-21</td>\n","      <td>united kingdom</td>\n","      <td>18929</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                   store_name         store_email  department  \\\n","0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n","1   2          Nordson Corporation                 NaN       Tools   \n","2   3        Stag Industrial, Inc.                 NaN      Beauty   \n","3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n","4   5  Mercantile Bank Corporation                 NaN        Baby   \n","\n","         income date_measured         country  days_ago  \n","0  $54438554.24    2006-02-04   united states      6862  \n","1  $41744177.01    2006-01-04  united kingdom      6893  \n","2  $36152340.34    2003-09-12   united states      7738  \n","3   $8928350.04    2006-05-08  united kingdom      6769  \n","4  $33552742.32    1973-01-21  united kingdom     18929  "]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Convert 'date_measured' to datetime format\n","df['date_measured'] = pd.to_datetime(df['date_measured'], format='%d-%m-%Y')\n","\n","\n","# Calculate the difference in days from the current date\n","current_date = pd.to_datetime(datetime.date.today())\n","df['days_ago'] = (current_date - df['date_measured']).dt.days\n","\n","# Display the first few rows to verify the 'days_ago' calculation\n","df.head()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
